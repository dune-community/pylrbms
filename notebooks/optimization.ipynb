{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "#from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "#from matplotlib import cm\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../scripts/OS2015_academic_problem.py\n",
    "\n",
    "config = {'num_coarse_grid_elements': [4, 4], \n",
    "          'num_grid_refinements': 2,\n",
    "          'num_grid_subdomains': [2, 2], \n",
    "          'num_grid_oversampling_layers': 4, # num_grid_oversampling_layers has to exactly cover one subdomain!\n",
    "          'initial_RB_order': 0,\n",
    "          'enrichment_target_error': 2.,\n",
    "          'marking_doerfler_theta': 0.33,\n",
    "          'marking_max_age': 2}\n",
    "\n",
    "grid_and_problem_data = init_grid_and_problem(config)\n",
    "\n",
    "mu_bar = grid_and_problem_data['mu_bar']\n",
    "parameter_range = grid_and_problem_data['parameter_range']\n",
    "parameter_range = (parameter_range[0], parameter_range[1])\n",
    "\n",
    "initial_guess = 0.5*(parameter_range[0] + parameter_range[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../scripts/discretize_elliptic.py\n",
    "\n",
    "d_blocked, block_space, local_boundary_info = discretize(grid_and_problem_data)\n",
    "d_blocked.disable_logging()\n",
    "mu_bar = d_blocked.parse_parameter(mu_bar)\n",
    "\n",
    "def detailed_quantity_of_interest(mu):\n",
    "    return d_blocked.rhs.apply(d_blocked.solve(mu)).data[0]\n",
    "\n",
    "print('computing some detailed quantities of interest:')\n",
    "\n",
    "training_set = d_blocked.parameter_space.sample_uniformly(5)\n",
    "training_set.extend(d_blocked.parameter_space.sample_randomly(10))\n",
    "training_set = [mu['diffusion'] for mu in training_set]\n",
    "training_set.sort()\n",
    "detailed_quantities_of_interest = [detailed_quantity_of_interest(mu) for mu in training_set]\n",
    "\n",
    "plt.plot(training_set, detailed_quantities_of_interest, '-o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('minimizing detailed quantity of interest ', end='')\n",
    "\n",
    "detailed_minimization_data = {'num_evals': 0,\n",
    "                              'all_evaluation_points': [],\n",
    "                              'evaluation_points': [initial_guess, ]}\n",
    "\n",
    "\n",
    "def quantity_of_interest(function, cfg, mu):\n",
    "    print('.', end='')\n",
    "    cfg['num_evals'] += 1\n",
    "    cfg['all_evaluation_points'].append(mu)\n",
    "    return function(mu)\n",
    "\n",
    "\n",
    "def postprocess(result, cfg, evaluate_qoi):\n",
    "    if (result.status != 0):\n",
    "        print(' failed!')\n",
    "    else:\n",
    "        print(' succeded!')\n",
    "        print('  x_min:    {}'.format(result.x))\n",
    "        print('  qoi(x_min): {}'.format(result.fun))\n",
    "        print('  num iterations:     {}'.format(result.nit))\n",
    "        print('  num function calls: {}'.format(cfg['num_evals']))\n",
    "\n",
    "        plt.plot(training_set, detailed_quantities_of_interest)\n",
    "        plt.plot(cfg['all_evaluation_points'], [evaluate_qoi(mu) for mu in cfg['all_evaluation_points']], 'o')\n",
    "\n",
    "result = minimize(partial(quantity_of_interest, detailed_quantity_of_interest, detailed_minimization_data),\n",
    "                  initial_guess,\n",
    "                  method='L-BFGS-B', jac=False,\n",
    "                  bounds=(parameter_range,),\n",
    "                  callback=lambda xk: detailed_minimization_data['evaluation_points'].append(xk),\n",
    "                  options={'ftol': 1e-15, 'gtol': 1e-15})\n",
    "\n",
    "postprocess(result, detailed_minimization_data, detailed_quantity_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('reducing with standard RB:', flush=True)\n",
    "\n",
    "from pymor.algorithms.greedy import greedy\n",
    "from pymor.discretizations.basic import StationaryDiscretization\n",
    "from pymor.parameters.functionals import GenericParameterFunctional\n",
    "from pymor.reductors.coercive import CoerciveRBReductor\n",
    "\n",
    "d_unblocked = StationaryDiscretization(\n",
    "    d_blocked.operators['global_op'], d_blocked.operators['global_rhs'],\n",
    "    products={'energy_dg_mu_bar': d_blocked.operators['global_op'].assemble(mu_bar)},\n",
    "    parameter_space=d_blocked.parameter_space,\n",
    "    name='unblocked_swipdg')\n",
    "\n",
    "def coercivity_estimator(mu):\n",
    "    return 1./np.sqrt(alpha(grid_and_problem_data['lambda']['coefficients'], mu, mu_bar))\n",
    "\n",
    "reductor_unblocked = CoerciveRBReductor(\n",
    "    d_unblocked,\n",
    "    product=d_unblocked.energy_dg_mu_bar_product,\n",
    "    coercivity_estimator=GenericParameterFunctional(coercivity_estimator,\n",
    "                                                    grid_and_problem_data['parameter_type']))\n",
    "\n",
    "greedy_data = greedy(d_unblocked, reductor_unblocked, training_set,\n",
    "                     extension_params={'method': 'gram_schmidt'},\n",
    "                     max_extensions=9999)\n",
    "\n",
    "print('took {} evaluations of the detailed discretization'.format(greedy_data['extensions']))\n",
    "print('maximum estimated model reduction error over training set: {}'.format(np.min(greedy_data['max_errs'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_unblocked = greedy_data['reduced_discretization']\n",
    "rd_unblocked.disable_logging()\n",
    "\n",
    "def reduced_quantity_of_interest(mu):\n",
    "    return rd_unblocked.rhs.apply(rd_unblocked.solve(mu)).data[0]\n",
    "\n",
    "print('computing some reduced quantities of interest ...')\n",
    "\n",
    "reduced_quantities_of_interest = [reduced_quantity_of_interest(mu) for mu in training_set]\n",
    "\n",
    "print('L-infty error of QoI: {}'.format(np.max(np.abs(  np.array(detailed_quantities_of_interest)\n",
    "                                                      - np.array(reduced_quantities_of_interest)))))\n",
    "\n",
    "plt.plot(training_set, detailed_quantities_of_interest)\n",
    "plt.plot(training_set, reduced_quantities_of_interest, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('minimizing reduced quantity of interest ', end='')\n",
    "\n",
    "reduced_minimization_data = {'num_evals': 0,\n",
    "                             'all_evaluation_points': [],\n",
    "                             'evaluation_points': [initial_guess, ]}\n",
    "\n",
    "result = minimize(partial(quantity_of_interest, reduced_quantity_of_interest, reduced_minimization_data),\n",
    "                  initial_guess,\n",
    "                  method='L-BFGS-B', jac=False,\n",
    "                  bounds=(parameter_range,),\n",
    "                  callback=lambda xk: reduced_minimization_data['evaluation_points'].append(xk),\n",
    "                  options={'ftol': 1e-15, 'gtol': 1e-15})\n",
    "\n",
    "postprocess(result, reduced_minimization_data, reduced_quantity_of_interest)\n",
    "plt.plot(detailed_minimization_data['all_evaluation_points'],\n",
    "         [detailed_quantity_of_interest(mu) for mu in detailed_minimization_data['all_evaluation_points']], 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is required to estimate the error tolerance for the online enrichment\n",
    "print('estimating some detailed errors:')\n",
    "detailed_errors = []                                                                                                                                                                                                      \n",
    "for mu in parameter_range:\n",
    "    mu = d_unblocked.parse_parameter(mu)\n",
    "    print('  {}: '.format(mu), end='', flush=True)\n",
    "    U = d_unblocked.solve(mu)\n",
    "    estimate = d_unblocked.estimate(U, mu=mu)\n",
    "    print(estimate)\n",
    "    detailed_errors.append(estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymor.core.exceptions import ExtensionError\n",
    "\n",
    "max_extension_error = 1.\n",
    "print('maximum extension error: {}'.format(max_extension_error))\n",
    "print('')\n",
    "\n",
    "%run ../scripts/offline.py\n",
    "\n",
    "reductor_blocked = init_local_reduced_bases(d_blocked, block_space, config['initial_RB_order'])\n",
    "\n",
    "#print('adding some global solution snapshots to reduced basis ...', flush=True)\n",
    "#for mu in parameter_range:\n",
    "#    U = d.solve(mu)\n",
    "#    try:\n",
    "#        reductor_blocked.extend_basis(U)\n",
    "#    except ExtensionError:\n",
    "#        pass                                                                                                                                                                                                     \n",
    "#print('')\n",
    "\n",
    "print('reducing:', flush=True)\n",
    "rd_blocked = reductor_blocked.reduce()\n",
    "rd_blocked = rd_blocked.with_(estimator=d_blocked.estimator)\n",
    "rd_blocked.disable_logging()\n",
    "print('initial reduced (LRBMS) system is of size {}x{}'.format(rd_blocked.solution_space.dim, rd_blocked.solution_space.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LRBMS_quantity_of_interest(mu):\n",
    "    return rd_blocked.rhs.apply(rd_blocked.solve(mu)).data[0]\n",
    "\n",
    "print('computing some (LRBMS) reduced quantities of interest ...')\n",
    "\n",
    "LRBMS_quantities_of_interest = [LRBMS_quantity_of_interest(mu) for mu in training_set]\n",
    "\n",
    "print('L-infty error w.r.t. detailed QoI: {}'.format(np.max(np.abs(  np.array(detailed_quantities_of_interest)\n",
    "                                                        - np.array(LRBMS_quantities_of_interest)))))\n",
    "print('L-infty error w.r.t reduced QoI: {}'.format(np.max(np.abs(  np.array(reduced_quantities_of_interest)\n",
    "                                                        - np.array(LRBMS_quantities_of_interest)))))\n",
    "\n",
    "plt.plot(training_set, detailed_quantities_of_interest)\n",
    "plt.plot(training_set, LRBMS_quantities_of_interest, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('minimizing reduced (LRBMS) quantity of interest ', end='')\n",
    "\n",
    "LRBMS_minimization_data = {'num_evals': 0,\n",
    "                           'all_evaluation_points': [],\n",
    "                           'evaluation_points': [initial_guess, ]}\n",
    "\n",
    "result = minimize(partial(quantity_of_interest, LRBMS_quantity_of_interest, LRBMS_minimization_data),\n",
    "                  initial_guess,\n",
    "                  method='L-BFGS-B', jac=False,\n",
    "                  bounds=(parameter_range,),\n",
    "                  callback=lambda xk: LRBMS_minimization_data['evaluation_points'].append(xk),\n",
    "                  options={'ftol': 1e-15, 'gtol': 1e-15})\n",
    "\n",
    "print(result)\n",
    "#postprocess(result, LRBMS_minimization_data, LRBMS_quantities_of_interest)\n",
    "#plt.plot(detailed_minimization_data['all_evaluation_points'],\n",
    "#         [LRBMS_quantities_of_interest(mu) for mu in LRBMS_minimization_data['all_evaluation_points']], 'x')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
