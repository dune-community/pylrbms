{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "#from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "#from matplotlib import cm\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setting up the reference discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../scripts/OS2015_academic_problem.py\n",
    "\n",
    "config = {'num_coarse_grid_elements': [4, 4], \n",
    "          'num_grid_refinements': 2,\n",
    "          'num_grid_subdomains': [2, 2], \n",
    "          'num_grid_oversampling_layers': 4, # num_grid_oversampling_layers has to exactly cover one subdomain!\n",
    "          'initial_RB_order': 0,\n",
    "          'enrichment_target_error': -1,\n",
    "          'marking_doerfler_theta': -1,\n",
    "          'marking_max_age': -1}\n",
    "\n",
    "grid_and_problem_data = init_grid_and_problem(config)\n",
    "\n",
    "mu_bar = grid_and_problem_data['mu_bar']\n",
    "parameter_range = grid_and_problem_data['parameter_range']\n",
    "parameter_range = (parameter_range[0], parameter_range[1])\n",
    "\n",
    "initial_guess = 0.5*(parameter_range[0] + parameter_range[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../scripts/discretize_elliptic.py\n",
    "\n",
    "block_SWIPDG_disc, block_space, enrichment_local_boundary_info = discretize(grid_and_problem_data)\n",
    "block_SWIPDG_disc.disable_logging()\n",
    "\n",
    "parameter_space = block_SWIPDG_disc.parameter_space\n",
    "parameter_type = block_SWIPDG_disc.parameter_type\n",
    "parse_parameter = block_SWIPDG_disc.parse_parameter\n",
    "mu_bar = parse_parameter(mu_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is required to estimate the target error for the online enrichment\n",
    "print('estimating some detailed errors:')\n",
    "detailed_errors = []\n",
    "for mu in parameter_range:\n",
    "    mu = parse_parameter(mu)\n",
    "    print('  {}: '.format(mu), end='', flush=True)\n",
    "    U = block_SWIPDG_disc.solve(mu)\n",
    "    estimate = block_SWIPDG_disc.estimate(U, mu=mu)\n",
    "    print(estimate)\n",
    "    detailed_errors.append(estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# as a result of the above, we set\n",
    "config['enrichment_target_error'] = 1.\n",
    "config['marking_doerfler_theta'] = 0.33\n",
    "config['marking_max_age'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# minimizing using the reference discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reference_quantity_of_interest(mu):\n",
    "    return block_SWIPDG_disc.rhs.apply(block_SWIPDG_disc.solve(mu)).data[0]\n",
    "\n",
    "print('computing some detailed quantities of interest ... ', end='')\n",
    "\n",
    "training_set = parameter_space.sample_uniformly(5)\n",
    "training_set.extend(parameter_space.sample_randomly(10))\n",
    "training_set = [mu['diffusion'] for mu in training_set]\n",
    "training_set.sort()\n",
    "reference_quantities_of_interest = [reference_quantity_of_interest(mu) for mu in training_set]\n",
    "\n",
    "print('done')\n",
    "\n",
    "plt.plot(training_set, reference_quantities_of_interest, '-o', label='QoI')\n",
    "plt.title('QoI over training set')\n",
    "plt.xlabel('parameter range')\n",
    "plt.ylabel('QoI')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('minimizing reference quantity of interest ', end='')\n",
    "\n",
    "reference_minimization_data = {'num_evals': 0,\n",
    "                               'all_evaluation_points': [],\n",
    "                               'evaluation_points': [initial_guess, ]}\n",
    "\n",
    "\n",
    "def quantity_of_interest(function, cfg, mu):\n",
    "    print('.', end='')\n",
    "    cfg['num_evals'] += 1\n",
    "    cfg['all_evaluation_points'].append(mu)\n",
    "    return function(mu)\n",
    "\n",
    "\n",
    "def report(result, evaluate_qoi, cfg):\n",
    "    if (result.status != 0):\n",
    "        print(' failed!')\n",
    "    else:\n",
    "        print(' succeded!')\n",
    "        print('  mu_min:    {}'.format(parse_parameter(result.x)))\n",
    "        print('  QoI(mu_min): {}'.format(result.fun[0]))\n",
    "        print('  num iterations:     {}'.format(result.nit))\n",
    "        print('  num function calls: {}'.format(cfg['num_evals']))\n",
    "\n",
    "result = minimize(partial(quantity_of_interest, reference_quantity_of_interest, reference_minimization_data),\n",
    "                  initial_guess,\n",
    "                  method='L-BFGS-B', jac=False,\n",
    "                  bounds=(parameter_range,),\n",
    "                  callback=lambda xk: reference_minimization_data['evaluation_points'].append(xk),\n",
    "                  options={'ftol': 1e-15, 'gtol': 1e-15})\n",
    "\n",
    "report(result, reference_quantity_of_interest, reference_minimization_data)\n",
    "\n",
    "plt.plot(training_set, reference_quantities_of_interest, label='QoI')\n",
    "plt.plot(reference_minimization_data['all_evaluation_points'],\n",
    "         [reference_quantity_of_interest(mu) for mu in reference_minimization_data['all_evaluation_points']],\n",
    "         'o', label='minimization points')\n",
    "plt.title('parameter values selected during optimization')\n",
    "plt.xlabel('paramter range')\n",
    "plt.ylabel('QoI')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setting up the standard RB discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('reducing with standard RB:', flush=True)\n",
    "\n",
    "from pymor.algorithms.greedy import greedy\n",
    "from pymor.discretizations.basic import StationaryDiscretization\n",
    "from pymor.parameters.functionals import GenericParameterFunctional\n",
    "from pymor.reductors.coercive import CoerciveRBReductor\n",
    "\n",
    "def coercivity_estimator(mu):\n",
    "    return 1./np.sqrt(alpha(grid_and_problem_data['lambda']['coefficients'], mu, mu_bar))\n",
    "\n",
    "SWIPDG_disc = StationaryDiscretization(\n",
    "    block_SWIPDG_disc.operators['global_op'],\n",
    "    block_SWIPDG_disc.operators['global_rhs'],\n",
    "    products={'energy_dg_mu_bar': block_SWIPDG_disc.operators['global_op'].assemble(mu_bar)},\n",
    "    parameter_space=parameter_space,\n",
    "    name='SWIPDG')\n",
    "\n",
    "RB_reductor = CoerciveRBReductor(\n",
    "    SWIPDG_disc,\n",
    "    product=SWIPDG_disc.energy_dg_mu_bar_product,\n",
    "    coercivity_estimator=GenericParameterFunctional(coercivity_estimator, parameter_type))\n",
    "\n",
    "RB_greedy_data = greedy(SWIPDG_disc, RB_reductor, training_set,\n",
    "                        extension_params={'method': 'gram_schmidt'},\n",
    "                        max_extensions=len(training_set))\n",
    "\n",
    "num_RB_greedy_extensions = RB_greedy_data['extensions']\n",
    "RB_greedy_mus, RB_greedy_errors = RB_greedy_data['max_err_mus'], RB_greedy_data['max_errs']\n",
    "RB_greedy_mus = [mu[0] for mu in RB_greedy_mus]\n",
    "\n",
    "print('RB system is of siez {}x{}'.format(num_RB_greedy_extensions, num_RB_greedy_extensions))\n",
    "print('maximum estimated model reduction error over training set: {}'.format(RB_greedy_errors[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RB_rd = RB_greedy_data['reduced_discretization']\n",
    "RB_rd.disable_logging()\n",
    "\n",
    "plt.plot(list(range(num_RB_greedy_extensions)) + [len(range(num_RB_greedy_extensions))],\n",
    "         RB_greedy_errors)\n",
    "plt.yscale('log')\n",
    "plt.title('error decay during greedy basis extension')\n",
    "plt.xlabel('greedy extension step')\n",
    "plt.ylabel('max estimted relative error over training set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# minimizing using the standard RB discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def RB_quantity_of_interest(mu):\n",
    "    return RB_rd.rhs.apply(RB_rd.solve(mu)).data[0]\n",
    "\n",
    "plt.plot(training_set, reference_quantities_of_interest, label='reference QoI')\n",
    "plt.scatter(RB_greedy_mus,\n",
    "            [RB_quantity_of_interest(mu) for mu in RB_greedy_mus],\n",
    "            s=np.exp(6.*np.linspace(1, 0.1, len(RB_greedy_mus))),\n",
    "            label='selected point')\n",
    "plt.title('parameter selection during greedy basis generation (larger: picked earlier)')\n",
    "plt.xlabel('paramter range')\n",
    "plt.ylabel('QoI')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('computing some RB quantities of interest ... ', end='')\n",
    "RB_quantities_of_interest = [RB_quantity_of_interest(mu) for mu in training_set]\n",
    "print('done')\n",
    "\n",
    "print('L-infty error of QoI over training set: {}'.format(\n",
    "    np.max(np.abs(np.array(reference_quantities_of_interest) - np.array(RB_quantities_of_interest)))\n",
    "))\n",
    "\n",
    "plt.plot(training_set, reference_quantities_of_interest, label='reference QoI')\n",
    "plt.plot(training_set, RB_quantities_of_interest, 'o', label='RB QoI')\n",
    "plt.title('comparison of reference and reduced QoI over training set')\n",
    "plt.xlabel('parameter range')\n",
    "plt.ylabel('QoI')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('minimizing reduced quantity of interest ', end='')\n",
    "\n",
    "RB_minimization_data = {'num_evals': 0,\n",
    "                        'all_evaluation_points': [],\n",
    "                        'evaluation_points': [initial_guess, ]}\n",
    "\n",
    "result = minimize(partial(quantity_of_interest, RB_quantity_of_interest, RB_minimization_data),\n",
    "                  initial_guess,\n",
    "                  method='L-BFGS-B', jac=False,\n",
    "                  bounds=(parameter_range,),\n",
    "                  callback=lambda xk: RB_minimization_data['evaluation_points'].append(xk),\n",
    "                  options={'ftol': 1e-15, 'gtol': 1e-15})\n",
    "\n",
    "report(result, RB_quantity_of_interest, RB_minimization_data)\n",
    "\n",
    "plt.plot(training_set, reference_quantities_of_interest, label='reference QoI')\n",
    "plt.plot(reference_minimization_data['all_evaluation_points'],\n",
    "         [reference_quantity_of_interest(mu) for mu in reference_minimization_data['all_evaluation_points']],\n",
    "         'o', label='reference minimization points')\n",
    "plt.plot(RB_minimization_data['all_evaluation_points'],\n",
    "         [RB_quantity_of_interest(mu) for mu in RB_minimization_data['all_evaluation_points']],\n",
    "         'kx', label='RB minimization points')\n",
    "plt.title('parameter values selected during optimization')\n",
    "plt.xlabel('paramter range')\n",
    "plt.ylabel('QoI')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setting up the LRBMS discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../scripts/offline.py\n",
    "\n",
    "LRBMS_reductor = init_local_reduced_bases(block_SWIPDG_disc, block_space, config['initial_RB_order'])\n",
    "\n",
    "#from pymor.core.exceptions import ExtensionError\n",
    "#\n",
    "#print('adding some global solution snapshots to reduced basis ...', flush=True)\n",
    "#for mu in parameter_range:\n",
    "#    U = d.solve(mu)\n",
    "#    try:\n",
    "#        reductor_blocked.extend_basis(U)\n",
    "#    except ExtensionError:\n",
    "#        pass\n",
    "#print('')\n",
    "\n",
    "print('reducing:', flush=True)\n",
    "LRBMS_rd = LRBMS_reductor.reduce()\n",
    "LRBMS_rd = LRBMS_rd.with_(estimator=block_SWIPDG_disc.estimator)\n",
    "LRBMS_rd.disable_logging()\n",
    "print('initial reduced (LRBMS) system is of size {}x{}'.format(LRBMS_rd.solution_space.dim, LRBMS_rd.solution_space.dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# minimizing using the LRBMS discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LRBMS_quantity_of_interest(mu):\n",
    "    return LRBMS_rd.rhs.apply(LRBMS_rd.solve(mu)).data[0]\n",
    "\n",
    "print('computing some initial LRBMS reduced quantities of interest ...')\n",
    "\n",
    "LRBMS_quantities_of_interest = [LRBMS_quantity_of_interest(mu) for mu in training_set]\n",
    "\n",
    "print('L-infty error w.r.t. reference QoI: {}'.format(\n",
    "    np.max(np.abs(np.array(reference_quantities_of_interest) - np.array(LRBMS_quantities_of_interest)))\n",
    "))\n",
    "print('L-infty error w.r.t RB QoI: {}'.format(\n",
    "    np.max(np.abs(np.array(RB_quantities_of_interest) - np.array(LRBMS_quantities_of_interest)))\n",
    "))\n",
    "\n",
    "plt.plot(training_set, reference_quantities_of_interest, label='reference QoI')\n",
    "plt.plot(training_set, RB_quantities_of_interest, 'o', label='RB QoI')\n",
    "plt.plot(training_set, LRBMS_quantities_of_interest, 'x', label='initial LRBMS QoI')\n",
    "plt.title('comparison of reference, RB and initial LRBMS QoI over training set')\n",
    "plt.xlabel('parameter range')\n",
    "plt.ylabel('QoI')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('minimizing initial LRBMS quantity of interest ', end='')\n",
    "\n",
    "LRBMS_minimization_data = {'num_evals': 0,\n",
    "                           'all_evaluation_points': [],\n",
    "                           'evaluation_points': [initial_guess, ]}\n",
    "\n",
    "result = minimize(partial(quantity_of_interest, LRBMS_quantity_of_interest, LRBMS_minimization_data),\n",
    "                  initial_guess,\n",
    "                  method='L-BFGS-B', jac=False,\n",
    "                  bounds=(parameter_range,),\n",
    "                  callback=lambda xk: LRBMS_minimization_data['evaluation_points'].append(xk),\n",
    "                  options={'ftol': 1e-15, 'gtol': 1e-15})\n",
    "\n",
    "report(result, LRBMS_quantities_of_interest, LRBMS_minimization_data)\n",
    "\n",
    "plt.plot(training_set, reference_quantities_of_interest, label='reference QoI')\n",
    "plt.plot(reference_minimization_data['all_evaluation_points'],\n",
    "         [reference_quantity_of_interest(mu) for mu in reference_minimization_data['all_evaluation_points']],\n",
    "         'o', label='reference minimization points')\n",
    "plt.plot(RB_minimization_data['all_evaluation_points'],\n",
    "         [RB_quantity_of_interest(mu) for mu in RB_minimization_data['all_evaluation_points']],\n",
    "         'kx', label='RB minimization points')\n",
    "plt.plot(LRBMS_minimization_data['all_evaluation_points'],\n",
    "         [LRBMS_quantity_of_interest(mu) for mu in LRBMS_minimization_data['all_evaluation_points']],\n",
    "         'o', label='LRBMS minimization points')\n",
    "plt.title('parameter values selected during optimization')\n",
    "plt.xlabel('paramter range')\n",
    "plt.ylabel('QoI')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
