{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.getcwd() + '/../scripts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "#from mpl_toolkits.mplot3d import Axes3D # required for 3d plots\n",
    "import matplotlib.pyplot as plt\n",
    "#from matplotlib import cm # required for colors\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "np.seterr(all='raise')\n",
    "\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymor.core.logger import set_log_levels\n",
    "set_log_levels({'online_adaptive_lrbms': 'DEBUG',\n",
    "                'OS2015_academic_problem': 'INFO',\n",
    "                'discretize_elliptic': 'INFO',\n",
    "                'offline': 'INFO',\n",
    "                'online_enrichment': 'INFO'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setting up the reference discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from OS2015_academic_problem import init_grid_and_problem\n",
    "\n",
    "config = {'num_coarse_grid_elements': [4, 4], \n",
    "          'num_grid_refinements': 2,\n",
    "          'num_grid_subdomains': [2, 2], \n",
    "          'num_grid_oversampling_layers': 4, # num_grid_oversampling_layers has to exactly cover one subdomain!\n",
    "          'initial_RB_order': 0,\n",
    "          'enrichment_target_error': -1,\n",
    "          'marking_doerfler_theta': -1,\n",
    "          'marking_max_age': -1}\n",
    "\n",
    "grid_and_problem_data = init_grid_and_problem(config)\n",
    "\n",
    "mu_bar = grid_and_problem_data['mu_bar']\n",
    "parameter_range = grid_and_problem_data['parameter_range']\n",
    "parameter_range = (parameter_range[0], parameter_range[1])\n",
    "\n",
    "initial_guess = 0.5*(parameter_range[0] + parameter_range[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from discretize_elliptic import discretize\n",
    "\n",
    "block_SWIPDG_disc, block_space, enrichment_local_boundary_info = discretize(grid_and_problem_data)\n",
    "block_SWIPDG_disc.disable_logging()\n",
    "\n",
    "parameter_space = block_SWIPDG_disc.parameter_space\n",
    "parameter_type = block_SWIPDG_disc.parameter_type\n",
    "parse_parameter = block_SWIPDG_disc.parse_parameter\n",
    "mu_bar = parse_parameter(mu_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is required to estimate the target error for the online enrichment\n",
    "print('estimating some detailed errors:')\n",
    "detailed_errors = []\n",
    "for mu in parameter_range:\n",
    "    mu = parse_parameter(mu)\n",
    "    print('  {}: '.format(mu), end='', flush=True)\n",
    "    U = block_SWIPDG_disc.solve(mu)\n",
    "    estimate = block_SWIPDG_disc.estimate(U, mu=mu)\n",
    "    print(estimate)\n",
    "    detailed_errors.append(estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# as a result of the above, we set\n",
    "config['enrichment_target_error'] = 1.\n",
    "config['marking_doerfler_theta'] = 0.33\n",
    "config['marking_max_age'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# minimizing using the reference discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reference_quantity_of_interest(mu):\n",
    "    return block_SWIPDG_disc.rhs.apply(block_SWIPDG_disc.solve(mu)).data[0]\n",
    "\n",
    "print('computing some detailed quantities of interest ... ', end='')\n",
    "\n",
    "training_set = parameter_space.sample_uniformly(5)\n",
    "training_set.extend(parameter_space.sample_randomly(10))\n",
    "training_set = [mu['diffusion'] for mu in training_set]\n",
    "training_set.sort()\n",
    "reference_quantities_of_interest = [reference_quantity_of_interest(mu) for mu in training_set]\n",
    "\n",
    "print('done')\n",
    "\n",
    "plt.plot(training_set, reference_quantities_of_interest, '-o', label='QoI')\n",
    "plt.title('QoI over training set')\n",
    "plt.xlabel('parameter range')\n",
    "plt.ylabel('QoI')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('minimizing reference quantity of interest ', end='')\n",
    "\n",
    "reference_minimization_data = {'num_evals': 0,\n",
    "                               'evaluations' : [],\n",
    "                               'evaluation_points': []}\n",
    "\n",
    "\n",
    "def quantity_of_interest(function, data, mu):\n",
    "    print('.', end='')\n",
    "    QoI = function(mu)\n",
    "    #print('QoI({}) = '.format(mu), end='', flush=True)\n",
    "    #print(QoI)\n",
    "    data['num_evals'] += 1\n",
    "    data['evaluation_points'].append(parse_parameter(mu)['diffusion'][0])\n",
    "    data['evaluations'].append(QoI)\n",
    "    return QoI\n",
    "\n",
    "\n",
    "def report(result, data):\n",
    "    if (result.status != 0):\n",
    "        print(' failed!')\n",
    "    else:\n",
    "        print(' succeded!')\n",
    "        print('  mu_min:    {}'.format(parse_parameter(result.x)))\n",
    "        print('  QoI(mu_min): {}'.format(result.fun[0]))\n",
    "        print('  num iterations:     {}'.format(result.nit))\n",
    "        print('  num function calls: {}'.format(data['num_evals']))\n",
    "\n",
    "result = minimize(partial(quantity_of_interest, reference_quantity_of_interest, reference_minimization_data),\n",
    "                  initial_guess,\n",
    "                  method='L-BFGS-B', jac=False,\n",
    "                  bounds=(parameter_range,),\n",
    "                  options={'ftol': 1e-15, 'gtol': 1e-15})\n",
    "\n",
    "report(result, reference_minimization_data)\n",
    "\n",
    "plt.plot(training_set, reference_quantities_of_interest, label='QoI')\n",
    "plt.plot(reference_minimization_data['evaluation_points'],\n",
    "         [reference_quantity_of_interest(mu) for mu in reference_minimization_data['evaluation_points']],\n",
    "         'o', label='minimization points')\n",
    "plt.title('parameter values selected during optimization')\n",
    "plt.xlabel('paramter range')\n",
    "plt.ylabel('QoI')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setting up the standard RB discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('reducing with standard RB:', flush=True)\n",
    "\n",
    "from pymor.algorithms.greedy import greedy\n",
    "from pymor.discretizations.basic import StationaryDiscretization\n",
    "from pymor.parameters.functionals import GenericParameterFunctional\n",
    "from pymor.reductors.coercive import CoerciveRBReductor\n",
    "\n",
    "from discretize_elliptic import alpha\n",
    "\n",
    "def coercivity_estimator(mu):\n",
    "    return 1./np.sqrt(alpha(grid_and_problem_data['lambda']['coefficients'], mu, mu_bar))\n",
    "\n",
    "SWIPDG_disc = StationaryDiscretization(\n",
    "    block_SWIPDG_disc.operators['global_op'],\n",
    "    block_SWIPDG_disc.operators['global_rhs'],\n",
    "    products={'energy_dg_mu_bar': block_SWIPDG_disc.operators['global_op'].assemble(mu_bar)},\n",
    "    parameter_space=parameter_space,\n",
    "    name='SWIPDG')\n",
    "\n",
    "RB_reductor = CoerciveRBReductor(\n",
    "    SWIPDG_disc,\n",
    "    product=SWIPDG_disc.energy_dg_mu_bar_product,\n",
    "    coercivity_estimator=GenericParameterFunctional(coercivity_estimator, parameter_type))\n",
    "\n",
    "RB_greedy_data = greedy(SWIPDG_disc, RB_reductor, training_set,\n",
    "                        extension_params={'method': 'gram_schmidt'},\n",
    "                        max_extensions=len(training_set))\n",
    "\n",
    "num_RB_greedy_extensions = RB_greedy_data['extensions']\n",
    "RB_greedy_mus, RB_greedy_errors = RB_greedy_data['max_err_mus'], RB_greedy_data['max_errs']\n",
    "RB_greedy_mus = [mu[0] for mu in RB_greedy_mus]\n",
    "\n",
    "print('RB system is of siez {}x{}'.format(num_RB_greedy_extensions, num_RB_greedy_extensions))\n",
    "print('maximum estimated model reduction error over training set: {}'.format(RB_greedy_errors[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RB_rd = RB_greedy_data['reduced_discretization']\n",
    "RB_rd.disable_logging()\n",
    "\n",
    "plt.plot(list(range(num_RB_greedy_extensions)) + [len(range(num_RB_greedy_extensions))],\n",
    "         RB_greedy_errors)\n",
    "plt.yscale('log')\n",
    "plt.title('error decay during greedy basis extension')\n",
    "plt.xlabel('greedy extension step')\n",
    "plt.ylabel('max estimted relative error over training set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# minimizing using the standard RB discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def RB_quantity_of_interest(mu):\n",
    "    return RB_rd.rhs.apply(RB_rd.solve(mu)).data[0]\n",
    "\n",
    "plt.plot(training_set, reference_quantities_of_interest, label='reference QoI')\n",
    "plt.scatter(RB_greedy_mus,\n",
    "            [0.9*np.min(reference_quantities_of_interest) for mu in RB_greedy_mus],\n",
    "            s=np.exp(6.*np.linspace(1, 0.1, len(RB_greedy_mus))),\n",
    "            label='selected point')\n",
    "plt.title('parameter selection during greedy basis generation (larger: picked earlier)')\n",
    "plt.xlabel('paramter range')\n",
    "plt.ylabel('QoI')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('computing some RB quantities of interest ... ', end='')\n",
    "RB_quantities_of_interest = [RB_quantity_of_interest(mu) for mu in training_set]\n",
    "print('done')\n",
    "\n",
    "print('L-infty error of QoI over training set: {}'.format(\n",
    "    np.max(np.abs(np.array(reference_quantities_of_interest) - np.array(RB_quantities_of_interest)))\n",
    "))\n",
    "\n",
    "plt.plot(training_set, reference_quantities_of_interest, label='reference QoI')\n",
    "plt.plot(training_set, RB_quantities_of_interest, 'o', label='RB QoI')\n",
    "plt.title('comparison of reference and reduced QoI over training set')\n",
    "plt.xlabel('parameter range')\n",
    "plt.ylabel('QoI')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('minimizing reduced quantity of interest ', end='')\n",
    "\n",
    "RB_minimization_data = {'num_evals': 0,\n",
    "                        'evaluations' : [],\n",
    "                        'evaluation_points': []}\n",
    "\n",
    "result = minimize(partial(quantity_of_interest, RB_quantity_of_interest, RB_minimization_data),\n",
    "                  initial_guess,\n",
    "                  method='L-BFGS-B', jac=False,\n",
    "                  bounds=(parameter_range,),\n",
    "                  options={'ftol': 1e-15, 'gtol': 1e-15})\n",
    "\n",
    "report(result, RB_minimization_data)\n",
    "\n",
    "plt.plot(training_set, reference_quantities_of_interest, label='reference QoI')\n",
    "plt.plot(reference_minimization_data['evaluation_points'],\n",
    "         [reference_quantity_of_interest(mu) for mu in reference_minimization_data['evaluation_points']],\n",
    "         'o', label='reference minimization points')\n",
    "plt.plot(RB_minimization_data['evaluation_points'],\n",
    "         [RB_quantity_of_interest(mu) for mu in RB_minimization_data['evaluation_points']],\n",
    "         'kx', label='RB minimization points')\n",
    "plt.title('parameter values selected during optimization')\n",
    "plt.xlabel('paramter range')\n",
    "plt.ylabel('QoI')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setting up the LRBMS discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from offline import init_local_reduced_bases\n",
    "\n",
    "LRBMS_reductor = init_local_reduced_bases(block_SWIPDG_disc, block_space, config['initial_RB_order'])\n",
    "\n",
    "#from pymor.core.exceptions import ExtensionError\n",
    "#\n",
    "#print('adding some global solution snapshots to reduced basis ...', flush=True)\n",
    "#for mu in parameter_range:\n",
    "#    U = d.solve(mu)\n",
    "#    try:\n",
    "#        reductor_blocked.extend_basis(U)\n",
    "#    except ExtensionError:\n",
    "#        pass\n",
    "#print('')\n",
    "\n",
    "print('reducing:', flush=True)\n",
    "LRBMS_rd = LRBMS_reductor.reduce()\n",
    "LRBMS_rd = LRBMS_rd.with_(estimator=block_SWIPDG_disc.estimator)\n",
    "LRBMS_rd.disable_logging()\n",
    "print('initial reduced (LRBMS) system is of size {}x{}'.format(LRBMS_rd.solution_space.dim,\n",
    "                                                               LRBMS_rd.solution_space.dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# minimizing using the LRBMS discretization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using the insufficient initial basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LRBMS_quantity_of_interest(mu):\n",
    "    return LRBMS_rd.rhs.apply(LRBMS_rd.solve(mu)).data[0]\n",
    "\n",
    "print('computing some initial LRBMS reduced quantities of interest ...')\n",
    "\n",
    "LRBMS_quantities_of_interest = [LRBMS_quantity_of_interest(mu) for mu in training_set]\n",
    "\n",
    "print('L-infty error w.r.t. reference QoI: {}'.format(\n",
    "    np.max(np.abs(np.array(reference_quantities_of_interest) - np.array(LRBMS_quantities_of_interest)))\n",
    "))\n",
    "print('L-infty error w.r.t RB QoI: {}'.format(\n",
    "    np.max(np.abs(np.array(RB_quantities_of_interest) - np.array(LRBMS_quantities_of_interest)))\n",
    "))\n",
    "\n",
    "plt.plot(training_set, reference_quantities_of_interest, label='reference QoI')\n",
    "plt.plot(training_set, RB_quantities_of_interest, 'o', label='RB QoI')\n",
    "plt.plot(training_set, LRBMS_quantities_of_interest, 'x', label='initial LRBMS QoI')\n",
    "plt.title('comparison of reference, RB and initial LRBMS QoI over training set')\n",
    "plt.xlabel('parameter range')\n",
    "plt.ylabel('QoI')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('minimizing initial LRBMS quantity of interest ', end='')\n",
    "\n",
    "LRBMS_minimization_data = {'num_evals': 0,\n",
    "                           'evaluations' : [],\n",
    "                           'evaluation_points': []}\n",
    "\n",
    "result = minimize(partial(quantity_of_interest, LRBMS_quantity_of_interest, LRBMS_minimization_data),\n",
    "                  initial_guess,\n",
    "                  method='L-BFGS-B', jac=False,\n",
    "                  bounds=(parameter_range,),\n",
    "                  options={'ftol': 1e-15, 'gtol': 1e-15})\n",
    "\n",
    "report(result, LRBMS_minimization_data)\n",
    "\n",
    "plt.plot(training_set, reference_quantities_of_interest, label='reference QoI')\n",
    "plt.plot(reference_minimization_data['evaluation_points'],\n",
    "         [reference_quantity_of_interest(mu) for mu in reference_minimization_data['evaluation_points']],\n",
    "         'o', label='reference minimization points')\n",
    "plt.plot(RB_minimization_data['evaluation_points'],\n",
    "         [RB_quantity_of_interest(mu) for mu in RB_minimization_data['evaluation_points']],\n",
    "         'kx', label='RB minimization points')\n",
    "plt.plot(LRBMS_minimization_data['evaluation_points'],\n",
    "         [LRBMS_quantity_of_interest(mu) for mu in LRBMS_minimization_data['evaluation_points']],\n",
    "         'o', label='LRBMS minimization points')\n",
    "plt.title('parameter values selected during optimization')\n",
    "plt.xlabel('paramter range')\n",
    "plt.ylabel('QoI')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using the adaptive online enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('minimizing adaptive LRBMS quantity of interest ', end='')\n",
    "\n",
    "from online_enrichment import AdaptiveEnrichment\n",
    "\n",
    "online_adaptive_LRBMS = AdaptiveEnrichment(grid_and_problem_data,\n",
    "                                           block_SWIPDG_disc, block_space, enrichment_local_boundary_info,\n",
    "                                           LRBMS_reductor, LRBMS_rd,\n",
    "                                           config['enrichment_target_error'],\n",
    "                                           config['marking_doerfler_theta'],\n",
    "                                           config['marking_max_age'])\n",
    "online_adaptive_LRBMS.disable_logging()\n",
    "for ii in ('online_enrichment',\n",
    "           'pymor.algorithms.gram_schmidt',\n",
    "           'pymor.reductors.system'):\n",
    "    set_log_levels({ii: 'WARN'})\n",
    "\n",
    "adaptive_LRBMS_minimization_data = {'num_evals': 0,\n",
    "                                    'evaluation_points': [],\n",
    "                                    'evaluations' : [],\n",
    "                                    'intermediate_evaluations' : [],\n",
    "                                    'intermediate_evaluation_points': [],\n",
    "                                    'num_local_solves': []}\n",
    "\n",
    "\n",
    "def adaptive_LRBMS_quantity_of_interest(mu):\n",
    "    \n",
    "    num_solves = [0]\n",
    "    \n",
    "    def callback(rd_, U_, mu_, data_):\n",
    "        adaptive_LRBMS_minimization_data['intermediate_evaluation_points'].append(mu_['diffusion'][0])\n",
    "        QoI = rd_.rhs.apply(U_).data[0]\n",
    "        adaptive_LRBMS_minimization_data['intermediate_evaluations'].append(QoI)\n",
    "        num_solves[0] += data_['local_problem_solves']\n",
    "\n",
    "    mu = parse_parameter(mu)\n",
    "    U, rd, _ = online_adaptive_LRBMS.solve(mu, callback=callback)\n",
    "    \n",
    "    adaptive_LRBMS_minimization_data['num_local_solves'].append(num_solves[0])\n",
    "    \n",
    "    return rd.rhs.apply(U).data[0]\n",
    "\n",
    "\n",
    "result = minimize(partial(quantity_of_interest,\n",
    "                          adaptive_LRBMS_quantity_of_interest,\n",
    "                          adaptive_LRBMS_minimization_data),\n",
    "                  initial_guess,\n",
    "                  method='L-BFGS-B', jac=False,\n",
    "                  bounds=(parameter_range,),\n",
    "                  options={'ftol': 1e-15, 'gtol': 1e-15})\n",
    "\n",
    "report(result, adaptive_LRBMS_minimization_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_set, reference_quantities_of_interest, label='reference QoI')\n",
    "plt.plot(reference_minimization_data['evaluation_points'],\n",
    "         [reference_quantity_of_interest(mu) for mu in reference_minimization_data['evaluation_points']],\n",
    "         'o', label='reference minimization points')\n",
    "plt.plot(adaptive_LRBMS_minimization_data['evaluation_points'],\n",
    "         [adaptive_LRBMS_quantity_of_interest(mu) for mu in adaptive_LRBMS_minimization_data['evaluation_points']],\n",
    "         'kx', label='adaptive LRBMS minimization points')\n",
    "plt.title('parameter values selected during optimization')\n",
    "plt.xlabel('paramter range')\n",
    "plt.ylabel('QoI')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_set, reference_quantities_of_interest, label='reference QoI')\n",
    "plt.scatter(adaptive_LRBMS_minimization_data['intermediate_evaluation_points'],\n",
    "            adaptive_LRBMS_minimization_data['intermediate_evaluations'],\n",
    "            s=1.*np.exp(6.*np.linspace(1, 0.1, len(adaptive_LRBMS_minimization_data['intermediate_evaluations']))),\n",
    "            c=adaptive_LRBMS_minimization_data['intermediate_evaluation_points'],\n",
    "            label='selected point')\n",
    "plt.title('selected parameter values and intermediate QoIs during optimization')\n",
    "plt.xlabel('paramter range')\n",
    "plt.ylabel('QoI')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adaptive_LRBMS_minimization_data['evaluation_points'])\n",
    "print(adaptive_LRBMS_minimization_data['num_local_solves'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
